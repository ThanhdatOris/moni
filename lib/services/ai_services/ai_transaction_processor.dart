import 'dart:convert';
import 'dart:io';

import 'package:get_it/get_it.dart';
import 'package:google_generative_ai/google_generative_ai.dart';
import 'package:logger/logger.dart';

import '../core/environment_service.dart';
import 'ai_helpers.dart';
import 'ocr_service.dart';

/// Handles transaction extraction from images
/// - OCR processing
/// - Image validation
/// - AI verification of OCR results
/// - Combine OCR + AI for best results
///
/// ‚ö†Ô∏è OCRService is created per-request and disposed after use
/// to prevent memory leak (ML Kit TextRecognizer ~30-50 MB native memory)
class AITransactionProcessor {
  final GenerativeModel _model;
  final Logger _logger = Logger();
  final GetIt _getIt; // ‚úÖ Use GetIt to create OCRService per-request

  AITransactionProcessor({required GenerativeModel model, required GetIt getIt})
    : _model = model,
      _getIt = getIt;

  /// Extract transaction from image using OCR + AI verification
  Future<Map<String, dynamic>> extractTransactionFromImage(
    File imageFile,
  ) async {
    // ‚úÖ Create OCRService instance for this request
    OCRService? ocrService;

    try {
      _logger.i('üì∏ Processing image for transaction extraction');

      // Create new OCRService instance (Factory pattern)
      ocrService = _getIt<OCRService>();

      // Step 1: Run OCR to extract text from image
      final String extractedText = await ocrService.extractTextFromImage(
        imageFile,
      );

      if (extractedText.isEmpty) {
        return {'success': false, 'error': 'Could not extract text from image'};
      }

      _logger.d('üìù OCR extracted ${extractedText.length} characters');

      // Step 2: Analyze extracted text with OCR service
      final ocrAnalysis = ocrService.analyzeReceiptText(extractedText);
      final int ocrConfidence = 75; // OCR base confidence

      // Step 3: If OCR analysis is confident, use it directly
      if (ocrConfidence >= 80) {
        _logger.i('‚úÖ OCR confidence high ($ocrConfidence%), using OCR results');
        return _buildResult(
          extractedText,
          ocrAnalysis,
          {},
          ocrConfidence,
          useAI: false,
        );
      }

      // Step 4: Use AI to verify and improve OCR results
      _logger.i('ü§ñ OCR confidence low ($ocrConfidence%), verifying with AI');
      final aiAnalysis = await _analyzeTextWithAI(extractedText, ocrAnalysis);

      // Step 5: Combine OCR and AI results
      return _buildResult(
        extractedText,
        ocrAnalysis,
        aiAnalysis,
        ocrConfidence,
        useAI: true,
      );
    } catch (e) {
      _logger.e('‚ùå Error extracting transaction from image: $e');
      return {'success': false, 'error': e.toString()};
    } finally {
      // ‚úÖ CRITICAL: Always dispose OCRService to free native memory
      // This prevents memory leak of ~30-50 MB from ML Kit TextRecognizer
      ocrService?.dispose();
      _logger.d('üßπ OCRService disposed (freed native memory)');
    }
  }

  /// Validate image before processing
  Future<bool> validateImageForProcessing(File imageFile) async {
    try {
      // Check file size (max 4MB)
      final fileSize = await imageFile.length();
      if (fileSize > 4 * 1024 * 1024) {
        throw Exception('·∫¢nh qu√° l·ªõn. Vui l√≤ng ch·ªçn ·∫£nh nh·ªè h∆°n 4MB.');
      }

      // Check file format
      final fileName = imageFile.path.toLowerCase();
      if (!fileName.endsWith('.jpg') &&
          !fileName.endsWith('.jpeg') &&
          !fileName.endsWith('.png')) {
        throw Exception(
          'ƒê·ªãnh d·∫°ng ·∫£nh kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. Vui l√≤ng ch·ªçn file JPG ho·∫∑c PNG.',
        );
      }

      return true;
    } catch (e) {
      _logger.e('Image validation failed: $e');
      rethrow;
    }
  }

  /// Analyze text with AI to verify OCR results
  Future<Map<String, dynamic>> _analyzeTextWithAI(
    String text,
    Map<String, dynamic> ocrAnalysis,
  ) async {
    try {
      final prompt =
          '''
Ph√¢n t√≠ch vƒÉn b·∫£n sau v√† tr√≠ch xu·∫•t th√¥ng tin giao d·ªãch. VƒÉn b·∫£n n√†y ƒë√£ ƒë∆∞·ª£c OCR t·ª´ ·∫£nh (c√≥ th·ªÉ l√† h√≥a ƒë∆°n ho·∫∑c th√¥ng b√°o ng√¢n h√†ng).

VƒÉn b·∫£n:
"""
$text
"""

K·∫øt qu·∫£ ban ƒë·∫ßu t·ª´ OCR:
- S·ªë ti·ªÅn g·ª£i √Ω: ${ocrAnalysis['suggestedAmount']}
- T√™n c·ª≠a h√†ng: ${ocrAnalysis['merchantName']}
- Lo·∫°i giao d·ªãch: ${ocrAnalysis['transactionType']}
- Danh m·ª•c g·ª£i √Ω: ${ocrAnalysis['categoryHint']}

QUAN TR·ªåNG - X√°c ƒë·ªãnh lo·∫°i vƒÉn b·∫£n v√† x·ª≠ l√Ω ph√π h·ª£p:

üì± N·∫æU L√Ä TH√îNG B√ÅO NG√ÇN H√ÄNG (SMS/App notification):
- T√¨m c√°c t·ª´ kh√≥a: "GD", "Giao dich", "Chuyen tien", "Nhan tien", "Thanh toan", "Rut tien", "Nap tien"
- L·∫§Y S·ªê TI·ªÄN GIAO D·ªäCH (transaction amount), KH√îNG L·∫§Y S·ªê D∆Ø (balance/so du)
- V√≠ d·ª•: "GD: -50,000 VND. So du: 1,500,000 VND" ‚Üí L·∫•y 50000, kh√¥ng l·∫•y 1500000
- S·ªë ti·ªÅn th∆∞·ªùng c√≥ d·∫•u +/- ph√≠a tr∆∞·ªõc
- S·ªë d∆∞ th∆∞·ªùng c√≥ t·ª´ "so du", "balance", "SD" k√®m theo

üßæ N·∫æU L√Ä H√ìA ƒê∆†N MUA B√ÅN (Receipt/Invoice):
- ∆Øu ti√™n t√¨m THEO TH·ª® T·ª∞ (t·ª´ quan tr·ªçng nh·∫•t ‚Üí √≠t quan tr·ªçng):
  1. "T·ªïng c·ªông", "Th√†nh ti·ªÅn", "Total", "Grand Total", "Amount Due", "T·ªïng thanh to√°n"
  2. N·∫øu c√≥ nhi·ªÅu m·ª•c, t√¨m s·ªë ti·ªÅn cu·ªëi c√πng SAU KHI ƒë√£:
     - C·ªông thu·∫ø (VAT, Tax, Thu·∫ø)
     - Tr·ª´ gi·∫£m gi√° (Discount, Gi·∫£m gi√°, Khuy·∫øn m·∫°i)
     - C·ªông ph√≠ d·ªãch v·ª• (Service charge)
  3. TR√ÅNH l·∫•y: "T·∫°m t√≠nh", "Subtotal", s·ªë ti·ªÅn t·ª´ng m√≥n ri√™ng l·∫ª

QUY T·∫ÆC CHUNG:
- N·∫øu c√≥ c·∫£ "T·∫°m t√≠nh: 100k" v√† "T·ªïng c·ªông: 110k" ‚Üí L·∫•y 110k
- N·∫øu c√≥ c·∫£ "Subtotal: 100k", "Tax: 10k", "Total: 110k" ‚Üí L·∫•y 110k
- V·ªõi nhi·ªÅu s·ªë ti·ªÅn, ∆∞u ti√™n s·ªë c√≥ nh√£n "Total", "T·ªïng", "Th√†nh ti·ªÅn"
- S·ªë ti·ªÅn th∆∞·ªùng ·ªü cu·ªëi h√≥a ƒë∆°n, sau c√°c d√≤ng chi ti·∫øt

Tr·∫£ v·ªÅ JSON v·ªõi format:
{
  "verified_amount": s·ªë_ti·ªÅn_ch√≠nh_x√°c (s·ªë nguy√™n, kh√¥ng d·∫•u ph·∫©y),
  "description": "m√¥ t·∫£ ng·∫Øn g·ªçn v·ªÅ giao d·ªãch",
  "category_suggestion": "danh m·ª•c ph√π h·ª£p b·∫±ng ti·∫øng Vi·ªát",
  "transaction_type": "expense" ho·∫∑c "income",
  "confidence_score": s·ªë t·ª´ 0-100,
  "notes": "ghi ch√∫ b·ªï sung (v√≠ d·ª•: ƒë√£ t√≠nh thu·∫ø 10%, gi·∫£m gi√° 5k)",
  "document_type": "bank_notification" ho·∫∑c "receipt"
}

Danh m·ª•c g·ª£i √Ω: ƒÇn u·ªëng, Di chuy·ªÉn, Mua s·∫Øm, Gi·∫£i tr√≠, Y t·∫ø, H·ªçc t·∫≠p, H√≥a ƒë∆°n, Chuy·ªÉn ti·ªÅn, Thu nh·∫≠p, L∆∞∆°ng, Kh√°c

V√ç D·ª§ PH√ÇN T√çCH:

V√≠ d·ª• 1 - Th√¥ng b√°o ng√¢n h√†ng:
"TK 9704229304857264 GD -18,000 VND luc 11:30 20/01. So du 2,456,789 VND"
‚Üí verified_amount: 18000 (kh√¥ng l·∫•y 2456789)
‚Üí document_type: "bank_notification"

V√≠ d·ª• 2 - H√≥a ƒë∆°n nhi·ªÅu m·ª•c:
"Com tam: 35,000
Nuoc ngot: 15,000
Tam tinh: 50,000
Thue VAT 10%: 5,000
Tong cong: 55,000"
‚Üí verified_amount: 55000 (kh√¥ng l·∫•y 50000 t·∫°m t√≠nh)
‚Üí document_type: "receipt"
''';

      final response = await _model.generateContent([Content.text(prompt)]);

      final responseText = response.text ?? '';
      final parsedResult = _parseAIAnalysisResponse(responseText);

      return parsedResult;
    } catch (e) {
      _logger.e('Error in AI analysis: $e');
      return {};
    }
  }

  /// Parse AI analysis response (JSON)
  Map<String, dynamic> _parseAIAnalysisResponse(String response) {
    try {
      // Find JSON in response
      final jsonStart = response.indexOf('{');
      final jsonEnd = response.lastIndexOf('}');

      if (jsonStart == -1 || jsonEnd == -1 || jsonEnd <= jsonStart) {
        return {};
      }

      final jsonString = response.substring(jsonStart, jsonEnd + 1);

      if (EnvironmentService.debugMode) {
        _logger.d('üîç AI Analysis JSON: ${jsonString.length} chars');
      }

      final dynamic decoded = jsonDecode(jsonString);
      if (decoded is! Map<String, dynamic>) {
        return {};
      }

      final Map<String, dynamic> data = Map<String, dynamic>.from(decoded);

      // Normalize keys and data types
      final double verifiedAmount = AIHelpers.parseAmount(
        data['verified_amount'],
      );
      final String description = (data['description'] ?? '').toString();
      final String categorySuggestion =
          (data['category_suggestion'] ?? data['category'] ?? '').toString();
      final String transactionType =
          (data['transaction_type'] ?? data['type'] ?? 'expense')
              .toString()
              .toLowerCase();
      final int confidenceScore = (() {
        final raw = data['confidence_score'] ?? data['confidence'];
        if (raw is int) return raw;
        if (raw is double) return raw.round();
        if (raw is String) return int.tryParse(raw) ?? 0;
        return 0;
      })();
      final String notes = (data['notes'] ?? data['note'] ?? '').toString();
      final String documentType = (data['document_type'] ?? 'receipt')
          .toString();

      return {
        'verified_amount': verifiedAmount,
        'description': description,
        'category_suggestion': categorySuggestion,
        'transaction_type': transactionType == 'income' ? 'income' : 'expense',
        'confidence_score': confidenceScore.clamp(0, 100),
        'notes': notes,
        'document_type': documentType,
      };
    } catch (e) {
      _logger.e('‚ùå Error parsing AI analysis response: $e');
      return {};
    }
  }

  /// Build final result combining OCR and AI
  Map<String, dynamic> _buildResult(
    String extractedText,
    Map<String, dynamic> ocrAnalysis,
    Map<String, dynamic> aiAnalysis,
    int ocrConfidence, {
    required bool useAI,
  }) {
    final amount = useAI && aiAnalysis.isNotEmpty
        ? (aiAnalysis['verified_amount'] ?? ocrAnalysis['suggestedAmount'])
        : ocrAnalysis['suggestedAmount'];

    final description = useAI && aiAnalysis.isNotEmpty
        ? (aiAnalysis['description'] ?? 'Giao d·ªãch t·ª´ h√≥a ƒë∆°n')
        : (ocrAnalysis['merchantName'] ?? 'Giao d·ªãch t·ª´ h√≥a ƒë∆°n');

    final category = useAI && aiAnalysis.isNotEmpty
        ? (aiAnalysis['category_suggestion'] ?? ocrAnalysis['categoryHint'])
        : ocrAnalysis['categoryHint'];

    final type = useAI && aiAnalysis.isNotEmpty
        ? (aiAnalysis['transaction_type'] ?? ocrAnalysis['transactionType'])
        : ocrAnalysis['transactionType'];

    // Calculate combined confidence
    final aiConfidence = aiAnalysis['confidence_score'] ?? 0;
    final combinedConfidence = useAI
        ? ((ocrConfidence + aiConfidence) / 2).round()
        : ocrConfidence;

    final notes = useAI && aiAnalysis.isNotEmpty
        ? (aiAnalysis['notes'] ?? '')
        : '';

    final documentType = useAI && aiAnalysis.isNotEmpty
        ? (aiAnalysis['document_type'] ?? 'receipt')
        : 'receipt';

    return {
      'success': true,
      'amount': amount,
      'description': description,
      'type': type,
      'category_suggestion': category,
      'date': DateTime.now().toIso8601String().split('T')[0],
      'confidence': combinedConfidence,
      'raw_text': extractedText,
      'processing_method': useAI ? 'OCR + AI' : 'OCR only',
      'note': notes.isNotEmpty ? notes : description,
      'category_name': category,
      'document_type': documentType,
    };
  }
}
